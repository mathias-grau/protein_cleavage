{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Project 2 : Protein Cleavage"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Samuel Gaudin et Mathias Grau**"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "On initialise les paramètres du modèle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 316,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "p=13 # 13 acides aminés avant la liaison clivée\n",
        "q=2 # 2 acides aminés après la liaison clivée"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Lecture des fichiers à traiter"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "On créé une fonction qui va permettre d'extraire les données utiles d'un des fichier $\\texttt{\\text.red}$ et qui renvoie un tableau de couples du type : $$\\textbf{(\"séquence d'acides aminés\",\"interprétation\")}$$\n",
        "\n",
        "On définie les séquences de protéines de la manière suivante : avec $\\mathcal{A}=\\{A,...Z\\}$ l'ensemble des acides aminés.\n",
        "\n",
        "Connaissant une séquence de protéine $(a_i)_{i \\in 0,..,l-1}$ et la position de son site de clivage $j$ : on peut définir la séquence:  $$a_{j-p}a_{j-p+1}...a_{j-1}a_{j}...a_{j+q-1} \\in \\mathcal{A}^{p+q} $$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 317,
      "metadata": {
        "id": "Wc53J3xjrwMx"
      },
      "outputs": [],
      "source": [
        "def parse_file(filename):\n",
        "    pairs = []  # Tableau pour stocker les couples de chaînes de caractères\n",
        "\n",
        "    with open(filename, 'r') as file:\n",
        "        lines = file.readlines() # lit le fichier et stocke chaque ligne dans une liste\n",
        "\n",
        "        # Parcourir les lignes en sautant de 3 en 3\n",
        "        for i in range(1, len(lines), 3):\n",
        "            line2 = lines[i].strip()\n",
        "            line3 = lines[i + 1].strip()\n",
        "            pair = (line2, line3)\n",
        "            pairs.append(pair)\n",
        "\n",
        "    return pairs, len(pairs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 318,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of lines : 1408\n",
            "5 first pairs : \n",
            "('MASKATLLLAFTLLFATCIARHQQRQQQQNQCQLQNIEALEPIEVIQAEA', 'SSSSSSSSSSSSSSSSSSSSCMMMMMMMMMMMMMMMMMMMMMMMMMMMMM')\n",
            "('MARSSLFTFLCLAVFINGCLSQIEQQSPWEFQGSEVWQQHRYQSPRACRLE', 'SSSSSSSSSSSSSSSSSSSSSCMMMMMMMMMMMMMMMMMMMMMMMMMMMMM')\n",
            "('MLVMAPRTVLLLLSAALALTETWAGSHSMRYFYTSVSRPGRGEPRFISVGYVDD', 'SSSSSSSSSSSSSSSSSSSSSSSSCMMMMMMMMMMMMMMMMMMMMMMMMMMMMM')\n",
            "('MKLSKSTLVFSALLVILAAASAAPANQFIKTSCTLTTYPAVCEQSLSAYAKT', 'SSSSSSSSSSSSSSSSSSSSSSCMMMMMMMMMMMMMMMMMMMMMMMMMMMMM')\n",
            "('MANKLFLVCATLALCFLLTNASIYRTVVEFEEDDASNPVGPRQRCQKEFQQ', 'SSSSSSSSSSSSSSSSSSSSSCMMMMMMMMMMMMMMMMMMMMMMMMMMMMM')\n"
          ]
        }
      ],
      "source": [
        "# Exemple d'utilisation avec un fichier \"red.txt\"\n",
        "filename = './data/SIG_13.red'\n",
        "pairs,N = parse_file(filename)\n",
        "print(f\"Number of lines : {N}\")\n",
        "print(f\"5 first pairs : \")\n",
        "for i in range (5):\n",
        "    print(pairs[i])"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Statistiques sur l'acide aminé correspondant au site de clivage"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 319,
      "metadata": {},
      "outputs": [],
      "source": [
        "def find_letters_at_c_position(pairs):\n",
        "    letters = []  # Tableau pour stocker les lettres correspondantes à l'emplacement 'C'\n",
        "\n",
        "    for pair in pairs:\n",
        "        line2 = pair[0]\n",
        "        line3 = pair[1]\n",
        "\n",
        "        # Recherche de l'emplacement de la lettre 'C' dans le deuxième élément du couple\n",
        "        c_index = line3.find('C')\n",
        "\n",
        "        if c_index != -1:\n",
        "            # Ajout de la lettre correspondante dans le premier élément du couple ainsi que sa position\n",
        "            letters.append((line2[c_index],c_index))\n",
        "\n",
        "    return letters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 320,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Pour la première paire : \n",
            "MASKATLLLAFTLLFATCIARHQQRQQQQNQCQLQNIEALEPIEVIQAEA \n",
            "SSSSSSSSSSSSSSSSSSSSCMMMMMMMMMMMMMMMMMMMMMMMMMMMMM \n",
            "On a la lettre R à la position 20\n"
          ]
        }
      ],
      "source": [
        "# Utilisation avec la liste de couples 'pairs'\n",
        "found_letters = find_letters_at_c_position(pairs)\n",
        "\n",
        "# Affichage des lettres trouvées\n",
        "\n",
        "print(f\"Pour la première paire : \\n{pairs[0][0]} \\n{pairs[0][1]} \\nOn a la lettre {found_letters[0][0]} à la position {found_letters[0][1]}\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "On compte désormais les occurrences de chaque acide aminé en tant que site de clivage."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 321,
      "metadata": {},
      "outputs": [],
      "source": [
        "def count_letter_occurrences(letter_positions):\n",
        "    letter_counts = {}  # Dictionnaire pour stocker les occurrences des lettres\n",
        "\n",
        "    for letter, _ in letter_positions:\n",
        "        if letter in letter_counts:\n",
        "            letter_counts[letter] += 1\n",
        "        else:\n",
        "            letter_counts[letter] = 1\n",
        "\n",
        "    return letter_counts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 322,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Lettre : R, Occurrence : 36\n",
            "Lettre : Q, Occurrence : 173\n",
            "Lettre : G, Occurrence : 65\n",
            "Lettre : A, Occurrence : 298\n",
            "Lettre : S, Occurrence : 116\n",
            "Lettre : F, Occurrence : 38\n",
            "Lettre : W, Occurrence : 11\n",
            "Lettre : Y, Occurrence : 27\n",
            "Lettre : V, Occurrence : 64\n",
            "Lettre : E, Occurrence : 125\n",
            "Lettre : H, Occurrence : 26\n",
            "Lettre : M, Occurrence : 17\n",
            "Lettre : I, Occurrence : 42\n",
            "Lettre : D, Occurrence : 100\n",
            "Lettre : L, Occurrence : 68\n",
            "Lettre : T, Occurrence : 49\n",
            "Lettre : N, Occurrence : 42\n",
            "Lettre : K, Occurrence : 70\n",
            "Lettre : P, Occurrence : 14\n",
            "Lettre : C, Occurrence : 27\n"
          ]
        }
      ],
      "source": [
        "# Utilisation avec le tableau de couples 'letter_positions'\n",
        "occurrences = count_letter_occurrences(found_letters)\n",
        "\n",
        "# Affichage des occurrences des lettres\n",
        "for letter, count in occurrences.items():\n",
        "    print(f\"Lettre : {letter}, Occurrence : {count}\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Statistique sur les *N* sous-séquences de peptides signaux"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "On dispose de $\\textit{N}$ séquences d'acides aminés avec un site de clivage connu. On extrait les peptides signals qui correspondent à une succession d'acides aminés de taille $\\textit{p+q}$ avec $\\textit{p}$ acides aminés avant le site de clivage et $\\textit{q}$ acides aminés après."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 323,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Pour la première paire : \n",
            "MASKATLLLAFTLLFATCIARHQQRQQQQNQCQLQNIEALEPIEVIQAEA \n",
            "SSSSSSSSSSSSSSSSSSSSCMMMMMMMMMMMMMMMMMMMMMMMMMMMMM \n",
            "On a la lettre R à la position 20 ce qui donne la sous-chaine \n",
            "LLAFTLLFATCIARH\n"
          ]
        }
      ],
      "source": [
        "def extract_substrings(pairs, p, q):\n",
        "    extracted_substrings = []  # Tableau pour stocker les sous-chaînes extraites\n",
        "\n",
        "    for pair in pairs:\n",
        "        line2 = pair[0]\n",
        "        line3 = pair[1]\n",
        "\n",
        "        # Recherche de l'emplacement de la lettre 'C' dans le deuxième élément du couple\n",
        "        c_index = line3.find('C')\n",
        "\n",
        "        if c_index != -1:\n",
        "            # Extraction des sous-chaînes dans le premier élément du couple\n",
        "            start_index = max(1, c_index-p)\n",
        "            end_index = min(len(line2), c_index + q )\n",
        "            substring = line2[start_index:end_index]\n",
        "            extracted_substrings.append(substring)\n",
        "\n",
        "    return extracted_substrings\n",
        "\n",
        "\n",
        "extracted_substrings_test = extract_substrings(pairs, p, q)\n",
        "\n",
        "print(f\"Pour la première paire : \\n{pairs[0][0]} \\n{pairs[0][1]} \\nOn a la lettre {found_letters[0][0]} à la position {found_letters[0][1]} ce qui donne la sous-chaine \\n{extracted_substrings_test[0]}\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "On va maintenant créer un dictionnaire afin de stocker le nombre d'occurence de chaque acide aminé par rapport à leur position dans le peptide signal"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 324,
      "metadata": {},
      "outputs": [],
      "source": [
        "def count_letter_occurrences_with_position(extracted_substrings):\n",
        "    letter_counts = {}  # Dictionnaire pour stocker les occurrences de chaque lettre et sa position\n",
        "\n",
        "    for substring in extracted_substrings:\n",
        "        for position, letter in enumerate(substring):\n",
        "            letter_position = (letter, position)\n",
        "\n",
        "            if letter_position in letter_counts:\n",
        "                letter_counts[letter_position] += 1\n",
        "            else:\n",
        "                letter_counts[letter_position] = 1\n",
        "\n",
        "    return letter_counts"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "On définie les fonction $\\textit{f}$ et $\\textit{c}$ comme énoncées dans l'énoncé, qui compte le nombre d'occurences de l'acide aminé $a\\in \\mathcal{A} $ à la position $i$.\n",
        "$$\\begin{array}{ccccc}\n",
        "c & : & \\mathcal{A},\\llbracket 0,p+q \\rrbracket & \\to & \\mathbb{N} \\\\\n",
        " & & (a,i) & \\mapsto & c(a,i) \\\\\n",
        "\\end{array}$$\n",
        "\n",
        "On créé la fonction $f$ définie dans le sujet qui calcul la fréquence d'apparition de l'acide aminé $a\\in \\mathcal{A}$ à la position $i$.\n",
        "$$\\begin{array}{ccccc}\n",
        "f & : & \\mathcal{A},\\llbracket 0,p+q \\rrbracket & \\to & \\mathbb{R} \\\\\n",
        " & & (a,i) & \\mapsto & \\frac{c(a,i)}{N} \\\\\n",
        "\\end{array}$$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 325,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Lettre : L, Position : 0, Occurrences : 460\n",
            "Lettre : L, Position : 1, Occurrences : 520\n",
            "Lettre : A, Position : 2, Occurrences : 178\n",
            "Lettre : F, Position : 3, Occurrences : 104\n",
            "Lettre : T, Position : 4, Occurrences : 56\n",
            "Lettre : L, Position : 5, Occurrences : 442\n",
            "Lettre : L, Position : 6, Occurrences : 393\n",
            "Lettre : F, Position : 7, Occurrences : 74\n",
            "Lettre : A, Position : 8, Occurrences : 193\n",
            "Lettre : T, Position : 9, Occurrences : 117\n",
            "Lettre : C, Position : 10, Occurrences : 71\n"
          ]
        }
      ],
      "source": [
        "# Utilisation avec la liste de sous-chaînes extraites 'extracted_substrings'\n",
        "occurrences_with_position = count_letter_occurrences_with_position(extracted_substrings_test)\n",
        "\n",
        "# Affichage des occurrences de chaque lettre avec sa position\n",
        "k=0\n",
        "for  letter_position, count in occurrences_with_position.items():\n",
        "    letter, position = letter_position\n",
        "    print(f\"Lettre : {letter}, Position : {position}, Occurrences : {count}\")\n",
        "    k+=1\n",
        "    if k>10:\n",
        "        break   "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 326,
      "metadata": {},
      "outputs": [],
      "source": [
        "def f(N,occurrences_with_position, lettre, position,alpha=0,d=1):\n",
        "    letter_position = (lettre, position)\n",
        "\n",
        "    if letter_position in occurrences_with_position:\n",
        "        return (occurrences_with_position[letter_position]+alpha)/(N+alpha*d)\n",
        "    else:\n",
        "        return alpha/(N+alpha*d)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 327,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fréquence d'occurrences de la lettre 'L' à la position 0: 0.3239634574841883\n"
          ]
        }
      ],
      "source": [
        "# Utilisation avec le dictionnaire 'occurrences_with_position'\n",
        "lettre = 'L'\n",
        "position = 0\n",
        "occurrence_count = f(N,occurrences_with_position, lettre, position,alpha=1,d=p+q)\n",
        "\n",
        "print(f\"Fréquence d'occurrences de la lettre '{lettre}' à la position {position}: {occurrence_count}\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "On implémente maintenant la fonction $g$ qui évalue la fréquence d'un acide aminé $a\\in \\mathcal{A} $ sans se soucier de sa position dans la chaine de caractère :\n",
        "$$\\begin{array}{ccccc}\n",
        "g & : & \\mathcal{A} & \\to & \\mathbb{R} \\\\\n",
        " & & a & \\mapsto & g(a) \\\\\n",
        "\\end{array}$$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 328,
      "metadata": {},
      "outputs": [],
      "source": [
        "def g(extracted_substrings, lettre, N, alpha=0,d=1):\n",
        "    occurrence_count = 0\n",
        "    for substring in extracted_substrings:\n",
        "        occurrence_count += substring.count(lettre)\n",
        "    if occurrence_count == 0:\n",
        "        return alpha/(N+alpha*d)\n",
        "    frequency = (occurrence_count +alpha )/ (N+alpha*d)\n",
        "    return frequency\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 329,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fréquence d'occurrence de la lettre 'L' par chaîne: 3.068868587491216\n"
          ]
        }
      ],
      "source": [
        "# Utilisation avec 'extracted_substrings'\n",
        "lettre = 'L'\n",
        "result = g(extracted_substrings_test, lettre, N,alpha=1,d=p+q)\n",
        "\n",
        "print(f\"Fréquence d'occurrence de la lettre '{lettre}' par chaîne: {result}\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "On implémente ensuite la fonction $s$ comme étant définie :\n",
        "\n",
        "$\\forall a \\in \\mathcal{A} \\, \\forall i  \\in \\llbracket 0,p+q \\rrbracket $\n",
        "$$\n",
        "\\begin{array}{ccccc}\n",
        "s & : & \\mathcal{A},\\llbracket 0,p+q \\rrbracket & \\to & \\mathbb{R} \\\\\n",
        " & & (a,i) & \\mapsto & log(f(a,i))-log(g(a)) \\\\\n",
        "\\end{array}$$\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 330,
      "metadata": {},
      "outputs": [],
      "source": [
        "def s(N,extract_substrings,lettre,position,alpha=1,d=1):\n",
        "    occurrences_with_position=count_letter_occurrences_with_position(extract_substrings)\n",
        "    return np.log(f(N,occurrences_with_position,lettre,position,alpha,d))-np.log(g(extract_substrings,lettre,N,alpha,d))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "On définie logiquement la fonction score suivante :\n",
        "Pour tout mot $$w=a_{j-p}a_{j-p+1}...a_{j-1}a_{j}...a_{j+q-1} \\in \\mathcal{A}^{p+q} $$\n",
        "On a le $q-1$ score défini par :\n",
        "$$\\begin{array}{ccccc}\n",
        "score & : & \\mathcal{A}^{p+q} & \\to & \\mathbb{R} \\\\\n",
        " & & w & \\mapsto & \\sum_{i=0}^{p+q-1} s(a_{i},i) \\\\\n",
        "\\end{array}$$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 331,
      "metadata": {},
      "outputs": [],
      "source": [
        "def score(w,N,extracted_substrings,alpha=1,d=1):\n",
        "    sum=0.0\n",
        "    for i in range(len(w)):\n",
        "        sum += s(N,extracted_substrings,w[i],i,alpha,d)\n",
        "    return sum"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 332,
      "metadata": {},
      "outputs": [],
      "source": [
        "def threshold_classifier(w, N, extracted_substrings, alpha=1, d=1, threshold_value=0):\n",
        "    print(\"Beginning Test\")\n",
        "    \n",
        "    score_sum = score(w, N, extracted_substrings, alpha, d)\n",
        "    \n",
        "    print(f\"Score : {score_sum}\")\n",
        "    print(f\"Threshold : {threshold_value}\")\n",
        "    \n",
        "    if score_sum >= threshold_value:\n",
        "        return 1  # Classe positive\n",
        "    else:\n",
        "        return 0  # Classe négative"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 351,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Le score minimal obtenu dans la substring SIG_13 est -48.24458384914466\n"
          ]
        }
      ],
      "source": [
        "from tqdm import tqdm\n",
        "# On calcule le minimum de score pour la séquence SIG_13\n",
        "min=0\n",
        "mot = ''\n",
        "for substring in tqdm(extracted_substrings_test):\n",
        "    score_sum = score(substring, N, extracted_substrings_test, alpha=1, d=p+q)\n",
        "    if score_sum<min:\n",
        "        min=score_sum\n",
        "        mot=substring\n",
        "\n",
        "# On obtient un score de -48.24458384914466 qui va servie de threshold pour la suite\n",
        "score_min= -48.24458384914466 \n",
        "print(f'Le score minimal obtenu dans la substring SIG_13 est {score_min}')"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Exemple d'utilisation de ce classifieur sur une chaine de caractère étant un peptide signal présent dans la séquence donnée"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 334,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test sur le potentiel peptide signal : LLAFTLLFATCIARH\n",
            "Beginning Test\n",
            "Score : -37.08975645397594\n",
            "Threshold : -48.24458384914466\n",
            "Réponse : 1\n"
          ]
        }
      ],
      "source": [
        "\n",
        "w='LLAFTLLFATCIARH' #qui est un mot de la sous-chaine SIG_13 donc un peptide  signal\n",
        "threshold_value = score_min\n",
        "\n",
        "score_obtenu = score(w, N, extracted_substrings_test, alpha=2, d=p+q)\n",
        "print(f\"Test sur le potentiel peptide signal : {w}\")\n",
        "test= threshold_classifier(w, N, extracted_substrings_test, alpha=1, d=p+q, threshold_value=threshold_value)\n",
        "print('Réponse :',test)\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Quelques SVM Kernels"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Vectorisation des données"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "On crée les vecteurs de taille $26(p+q)$ qui est la concatenation de $p+q$ vecteurs de taille $26$ où la ième valeur est $1$ si elle correspond à la lettre considérée (dans l'ordre alphabétique) et $0$ sinon."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 335,
      "metadata": {},
      "outputs": [],
      "source": [
        "import string\n",
        "def create_encoded_vectors(substring_extracted, p, q):\n",
        "    alphabet = string.ascii_uppercase\n",
        "    letter_to_index = {letter: index for index, letter in enumerate(alphabet)}\n",
        "\n",
        "    encoded_vectors = []\n",
        "    for substring in substring_extracted:\n",
        "        vector = np.zeros(26 * (p + q))\n",
        "\n",
        "        for i, letter in enumerate(substring):\n",
        "            if letter in letter_to_index:\n",
        "                index = letter_to_index[letter]\n",
        "                vector[i * 26 + index] = 1\n",
        "\n",
        "        encoded_vectors.append(vector)\n",
        "\n",
        "    return encoded_vectors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 353,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "First extracted substring     LLAFTLLFATCIARH\n",
            "First extracted vector  [0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0\n",
            " 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "Verification LLAFTLLFATCIARH\n"
          ]
        }
      ],
      "source": [
        "print(f\"First extracted substring     {extracted_substrings_test[0]}\")\n",
        "alphabet = string.ascii_uppercase\n",
        "letter_to_index = {letter: index for index, letter in enumerate(alphabet)}\n",
        "encoded_vector = create_encoded_vectors(extracted_substrings_test, p, q)[0]\n",
        "print(f\"First extracted vector  {encoded_vector.astype(int)}\")\n",
        "indices = np.argwhere(encoded_vector == 1).flatten()%26\n",
        "\n",
        "print(f'Verification {\"\".join([alphabet[indices[i]] for i in range(len(indices))])}')"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Le produit scalaire entre 2 vecteurs donne le nombre de lettres communes entre les 2 chaines de caractères "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 337,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "First extracted substring     LLAFTLLFATCIARH\n",
            "Second extracted substring    FLCLAVFINGCLSQI\n",
            "Number of common letters : 2.0\n"
          ]
        }
      ],
      "source": [
        "print(f\"First extracted substring     {extracted_substrings_test[0]}\")\n",
        "print(f\"Second extracted substring    {extracted_substrings_test[1]}\")\n",
        "\n",
        "first_extracted_vector = create_encoded_vectors(extracted_substrings_test, p, q)[0]\n",
        "second_extracted_vector = create_encoded_vectors(extracted_substrings_test, p, q)[1]\n",
        "\n",
        "num_common_letters = np.sum(first_extracted_vector * second_extracted_vector)\n",
        "\n",
        "print(f\"Number of common letters : {num_common_letters}\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Matrice de probabilité"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "On définit la matrice de probabilité $M(x,y)$ pour toute paire d'acide aminé $(x,y)$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 338,
      "metadata": {},
      "outputs": [],
      "source": [
        "def similarity_matrix(string1,string2):\n",
        "    alphabet = string.ascii_uppercase\n",
        "    letter_to_index = {letter: index for index, letter in enumerate(alphabet)}  \n",
        "    matrix=np.zeros((len(alphabet),len(alphabet)))\n",
        "    for i in range(len(string1)):\n",
        "        indice1=letter_to_index[str(string1[i])]\n",
        "        indice2=letter_to_index[str(string2[i])]\n",
        "        if indice1==indice2:\n",
        "            matrix[indice1][indice2]+=1\n",
        "        else :\n",
        "            matrix[indice1][indice2]+=1\n",
        "            matrix[indice2][indice1]+=1\n",
        "    return matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 339,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Matrice de similitude entre LLAFTLLFATCIARH et FLCLAVFINGCLSQI :\n",
            "[[0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 1 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 1 0 0 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 1 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 3 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0]\n",
            " [1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\n"
          ]
        }
      ],
      "source": [
        "word1=extracted_substrings_test[0]\n",
        "word2=extracted_substrings_test[1] \n",
        "sim_matrix=similarity_matrix(word1,word2)\n",
        "print(f'Matrice de similitude entre {word1} et {word2} :')\n",
        "print(sim_matrix.astype(int))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "On définit maintenant le score de similarité entre 2 séquences d'acides aminés en prenant la trace de la matrice de similarité : \n",
        "$$\n",
        "\\begin{array}{ccccc}\n",
        "S & : & \\mathcal{A}^{p+q},\\mathcal{A}^{p+q} & \\to & \\mathbb{N} \\\\\n",
        " & & (a,b) & \\mapsto & \\sum_{i=0}^{n-1} M(a_i,b_i) \\\\\n",
        "\\end{array}$$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 340,
      "metadata": {},
      "outputs": [],
      "source": [
        "def S(string1,string2):\n",
        "    return np.trace(similarity_matrix(string1,string2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 341,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of common letters at the same position by getting the trace of the similarity matrix : 2.0\n"
          ]
        }
      ],
      "source": [
        "print(f\"Number of common letters at the same position by getting the trace of the similarity matrix : {S(word1,word2)}\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "On définit finalement la fonction $log-kernel$ comme suit :\n",
        "$$ logK(a,b)=\\sum_{i=-p}^{q-1}\\phi_i(a_{p+i},b_{p+i})$$\n",
        "où\n",
        "$$\\phi_i(x,y)= \n",
        "\\left\\{\n",
        "    \\begin{array}{ll}\n",
        "        s(x,i)+s(y,i) & si \\; x\\neq y \\\\\n",
        "        s(x,i)+log(1+e^{s(x,i)}) & si \\; x=y\n",
        "    \\end{array}\n",
        "\\right.$$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 342,
      "metadata": {},
      "outputs": [],
      "source": [
        "def log_kernel(a,b, N, extracted_substring,p,q,alpha=1):\n",
        "    sum=0.0\n",
        "    d=p+q\n",
        "    for i in range(len(a)):\n",
        "        if a[i]!=b[i]:\n",
        "            sum+=s(N,extracted_substring,a[i],i-p,alpha,d)+s(N,extracted_substring,b[i],i-p,alpha,d)\n",
        "        else:\n",
        "            sum+=s(N,extracted_substring,a[i],i-p,alpha,d)+np.log(1+np.exp(s(N,extracted_substring,a[i],i-p,alpha,d)))\n",
        "            \n",
        "    return (sum)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 343,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Résultat : -177.43938709139957 pour le mot LLAFTLLFATCIARH et FLCLAVFINGCLSQI\n"
          ]
        }
      ],
      "source": [
        "res = log_kernel(word1, word2, N, extracted_substrings_test, p, q,alpha=2)\n",
        "print(f'Résultat : {res} pour le mot {word1} et {word2}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 354,
      "metadata": {},
      "outputs": [],
      "source": [
        "def create_substrings_dataset(pairs, p, q):\n",
        "    extracted_substrings = []  # Tableau pour stocker les sous-chaînes extraites\n",
        "\n",
        "    for pair in pairs:\n",
        "        line2 = pair[0]\n",
        "        line3 = pair[1]\n",
        "\n",
        "        # Recherche de l'emplacement de la lettre 'C' dans le deuxième élément du couple\n",
        "        c_index = line3.find('C')\n",
        "        \n",
        "        shift = np.random.choice([-4, 0, 4],p=[0.1, 0.8, 0.1]) \n",
        "        # On tire un nombre aléatoire entre -4, 0 et 4 \n",
        "        # avec une probabilité de 0.1, 0.8 et 0.1 \n",
        "        # respectivement pour décaler ou non la sous-chaîne extraite\n",
        "        \n",
        "        if shift == 0:\n",
        "            y=1\n",
        "        else:\n",
        "            y=0\n",
        "\n",
        "        if c_index != -1 and c_index + shift >= 0 and c_index + shift < len(line2):\n",
        "            # Extraction des sous-chaînes dans le premier élément du couple\n",
        "            start_index = max(1, c_index-p+shift)\n",
        "            end_index = min(len(line2), c_index + q+shift) \n",
        "            substring = line2[start_index:end_index]\n",
        "            extracted_substrings.append((substring,y))\n",
        "\n",
        "    return extracted_substrings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 345,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[('LLAFTLLFATCIARH', 1), ('FLCLAVFINGCLSQI', 1), ('LLSAALALTETWAGS', 1)]\n"
          ]
        }
      ],
      "source": [
        "extracted_substring_set_test = create_substrings_dataset(pairs, p, q)\n",
        "print(extracted_substring_set_test[:3])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 346,
      "metadata": {},
      "outputs": [],
      "source": [
        "test = []\n",
        "for i in range(N):\n",
        "    test.append(extracted_substring_set_test[i][0])\n",
        "extracted_substring_vectorised = create_encoded_vectors(test, p, q)\n",
        "extracted_substring_set_vectorised=[]\n",
        "for i in range(N):\n",
        "    extracted_substring_set_vectorised.append((extracted_substring_vectorised[i],extracted_substring_set_test[i][1]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 347,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy : 0.8546099290780141\n"
          ]
        }
      ],
      "source": [
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "training_rate=0.8 # Taux d'exemples d'entraînement\n",
        "\n",
        "X_train = []  # Caractéristiques des exemples d'entraînement\n",
        "y_train = []  # Étiquettes des exemples d'entraînement  \n",
        "X_test = []   # Caractéristiques des exemples de test\n",
        "y_test = []   # Étiquettes des exemples de test\n",
        "\n",
        "# Préparation des données d'entraînement et de test\n",
        "for i in range(int(training_rate*N)):\n",
        "    X_train.append(extracted_substring_set_vectorised[i][0])  # Caractéristiques des exemples d'entraînement\n",
        "    y_train.append(extracted_substring_set_vectorised[i][1])  # Étiquettes des exemples d'entraînement\n",
        "for i in range(int(training_rate*N),N):\n",
        "    X_test.append(extracted_substring_set_vectorised[i][0])   # Caractéristiques des exemples de test\n",
        "    y_test.append(extracted_substring_set_vectorised[i][1])   # Étiquettes des exemples de test\n",
        "\n",
        "# Création du modèle SVM avec un kernel gaussien (RBF)\n",
        "svm_model = SVC(kernel='rbf')\n",
        "\n",
        "# Entraînement du modèle\n",
        "svm_model.fit(X_train, y_train)\n",
        "\n",
        "# Prédiction des classes des exemples de test\n",
        "y_pred = svm_model.predict(X_test)\n",
        "\n",
        "# Évaluation du modèle\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Accuracy : {accuracy}\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Etude pour la fonction rbf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 361,
      "metadata": {},
      "outputs": [],
      "source": [
        "def svm(kernel):\n",
        "    filenames = ['./data/SIG_13.red','./data/EUKSIG_13.red','./data/GRAM-SIG_13.red','./data/GRAM+SIG_13.red']\n",
        "    print(f\"Kernel : {kernel}\")\n",
        "    print()\n",
        "    for i,filename in enumerate(filenames):\n",
        "        pairs,N = parse_file(filename)\n",
        "        extracted_substring_set_test = create_substrings_dataset(pairs, p, q)\n",
        "        test = []\n",
        "        for i in range(N):\n",
        "            test.append(extracted_substring_set_test[i][0])\n",
        "        extracted_substring_vectorised = create_encoded_vectors(test, p, q)\n",
        "        extracted_substring_set_vectorised=[]\n",
        "        for i in range(N):\n",
        "            extracted_substring_set_vectorised.append((extracted_substring_vectorised[i],extracted_substring_set_test[i][1]))\n",
        "        X_train = []  # Caractéristiques des exemples d'entraînement\n",
        "        y_train = []  # Étiquettes des exemples d'entraînement  \n",
        "        X_test = []   # Caractéristiques des exemples de test\n",
        "        y_test = []   # Étiquettes des exemples de test\n",
        "\n",
        "        # Préparation des données d'entraînement et de test\n",
        "        for i in range(int(training_rate*N)):\n",
        "            X_train.append(extracted_substring_set_vectorised[i][0])  # Caractéristiques des exemples d'entraînement\n",
        "            y_train.append(extracted_substring_set_vectorised[i][1])  # Étiquettes des exemples d'entraînement\n",
        "        for i in range(int(training_rate*N),N):\n",
        "            X_test.append(extracted_substring_set_vectorised[i][0])   # Caractéristiques des exemples de test\n",
        "            y_test.append(extracted_substring_set_vectorised[i][1])   # Étiquettes des exemples de test\n",
        "\n",
        "        # Création du modèle SVM avec un kernel gaussien (RBF)\n",
        "        svm_model = SVC(kernel=kernel)\n",
        "\n",
        "        # Entraînement du modèle\n",
        "        svm_model.fit(X_train, y_train)\n",
        "\n",
        "        # Prédiction des classes des exemples de test\n",
        "        y_pred = svm_model.predict(X_test)\n",
        "\n",
        "        # Évaluation du modèle\n",
        "        accuracy = accuracy_score(y_test, y_pred)\n",
        "        print(f'Filename : {filename}')\n",
        "        print(f\"Accuracy : {accuracy}\")\n",
        "        print(f'False positive rate : {1-accuracy}')\n",
        "        print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 362,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Kernel : rbf\n",
            "\n",
            "Filename : ./data/SIG_13.red\n",
            "Accuracy : 0.8262411347517731\n",
            "False positive rate : 0.17375886524822692\n",
            "\n",
            "Filename : ./data/EUKSIG_13.red\n",
            "Accuracy : 0.8706467661691543\n",
            "False positive rate : 0.12935323383084574\n",
            "\n",
            "Filename : ./data/GRAM-SIG_13.red\n",
            "Accuracy : 0.8490566037735849\n",
            "False positive rate : 0.15094339622641506\n",
            "\n",
            "Filename : ./data/GRAM+SIG_13.red\n",
            "Accuracy : 0.8571428571428571\n",
            "False positive rate : 0.1428571428571429\n",
            "\n"
          ]
        }
      ],
      "source": [
        "svm('rbf')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 363,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Kernel : linear\n",
            "\n",
            "Filename : ./data/SIG_13.red\n",
            "Accuracy : 0.875886524822695\n",
            "False positive rate : 0.12411347517730498\n",
            "\n",
            "Filename : ./data/EUKSIG_13.red\n",
            "Accuracy : 0.8756218905472637\n",
            "False positive rate : 0.12437810945273631\n",
            "\n",
            "Filename : ./data/GRAM-SIG_13.red\n",
            "Accuracy : 0.9433962264150944\n",
            "False positive rate : 0.05660377358490565\n",
            "\n",
            "Filename : ./data/GRAM+SIG_13.red\n",
            "Accuracy : 0.8214285714285714\n",
            "False positive rate : 0.1785714285714286\n",
            "\n"
          ]
        }
      ],
      "source": [
        "svm('linear')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 364,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Kernel : sigmoid\n",
            "\n",
            "Filename : ./data/SIG_13.red\n",
            "Accuracy : 0.900709219858156\n",
            "False positive rate : 0.099290780141844\n",
            "\n",
            "Filename : ./data/EUKSIG_13.red\n",
            "Accuracy : 0.8557213930348259\n",
            "False positive rate : 0.14427860696517414\n",
            "\n",
            "Filename : ./data/GRAM-SIG_13.red\n",
            "Accuracy : 0.9433962264150944\n",
            "False positive rate : 0.05660377358490565\n",
            "\n",
            "Filename : ./data/GRAM+SIG_13.red\n",
            "Accuracy : 0.8214285714285714\n",
            "False positive rate : 0.1785714285714286\n",
            "\n"
          ]
        }
      ],
      "source": [
        "svm('sigmoid')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 365,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Kernel : poly\n",
            "\n",
            "Filename : ./data/SIG_13.red\n",
            "Accuracy : 0.7943262411347518\n",
            "False positive rate : 0.2056737588652482\n",
            "\n",
            "Filename : ./data/EUKSIG_13.red\n",
            "Accuracy : 0.8059701492537313\n",
            "False positive rate : 0.19402985074626866\n",
            "\n",
            "Filename : ./data/GRAM-SIG_13.red\n",
            "Accuracy : 0.7358490566037735\n",
            "False positive rate : 0.26415094339622647\n",
            "\n",
            "Filename : ./data/GRAM+SIG_13.red\n",
            "Accuracy : 0.6071428571428571\n",
            "False positive rate : 0.3928571428571429\n",
            "\n"
          ]
        }
      ],
      "source": [
        "svm('poly')"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Conclusion"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Nous sommes donc parvenus à étudier des peptides signaux de longueur $p+q$ pour en faire des ensembles d'entrainement afin de pouvoir juger si une séquence aléatoire consitue, ou non, un peptide signal. Les taux de précision sont aux alentour de $90\\%$ pour les dataset utilisés "
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
